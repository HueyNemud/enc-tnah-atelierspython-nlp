{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .renbox {\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        padding: 2px;\n",
    "        margin: 3px;\n",
    "        border-radius: 3px;\n",
    "        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        font-weight: bolder;\n",
    "        background-color: #8b8c8b;\n",
    "    }\n",
    "    .per {\n",
    "        background-color: #ffb654;\n",
    "    }\n",
    "    .org {\n",
    "        background-color: #49ace6;\n",
    "    }\n",
    "    .misc {\n",
    "        background-color: #c2ccd1;\n",
    "    }\n",
    "    .loc {\n",
    "        background-color: #3deb6c;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "# Partie 1 : Entraîner un modèle de reconnaissance d'entités nommées avec SpaCy\n",
    "\n",
    "Bonjour 👋 !\n",
    "\n",
    "Bienvenue dans la première partie de la séquence dédiée à l'expérimentation du **traitement automatique du langage naturel** (TALN) grâce à un **modèle d'apprentissage profond**.\n",
    "\n",
    "\n",
    "## Objectifs de la séance 🎯\n",
    "- découvrir la reconnaissance d'entités nommées (REN)\n",
    "- utiliser et entraîner un modèle REN avec la bibliothèque Python `SpaCy`\n",
    "- découvrir le liage d'entités et l'expérimenter avec DBPedia\n",
    "- apprendre à requêter une API Web avec la bibliothèque Python `requests`\n",
    "- découvrir SPARQL, le langage d'interrogation du Web de données\n",
    "- construire une carte dynamique avec la bibliothèque Python `folium`\n",
    "\n",
    "## Important ❗\n",
    "\n",
    "1. Répondez aux questions directement dans les cellules de ce notebook.\n",
    "\n",
    "2. 🆘 Une question n'est pas claire ? Vous êtes bloqué(e) ?  N'attendez pas, **appelez à l'aide 🙋**.  \n",
    "\n",
    "3. 🤖 Vous pouvez utiliser ChatGPT/Gemini/etc. pour vous aider, **mais** contraignez vous à n'utiliser ses propositions **que si vous les comprenez vraiment**. Ne devenez pas esclave de la machine ! 🙏\n",
    "\n",
    "4. 😌 Si vous n'avez pas réussi ou pas eu le temps de répondre à une question, **pas de panique**, le répertoire `correction/` contient une solution !\n",
    "\n",
    "ℹ️ **Info** : La difficulté d'une question **🧩**  est indiquée de ⭐ à ⭐⭐⭐⭐.\n",
    "\n",
    "# A/ Introduction à la reconnaissance d'entités nommées\n",
    "\n",
    "## Présentation exemplifiée 🔬\n",
    "La reconnaissance d'entités nommées (REN) (en anglais *Named Entity Recognition*, ou NER) est une technique clé du traitement automatique du langage naturel (TALN). \n",
    "Elle consiste à **(1) identifier** et **(2) classer** automatiquement les **mentions d'entités du monde (réel ou fictif) dans un texte**.\n",
    "\n",
    "Prenons l'extrait suivant : \n",
    "\n",
    "> « Le capitaine Smith qui commandait le Titanic est, nous l'avons dit hier, depuis plus de 35 ans au service de la White Star Line.\n",
    "> Il est actuellement agé de 60 ans.\n",
    ">  Né dans le Staffordshire, le capitaine Smith avait fait son apprentissage de marin dans la maison d'armement Gibson et C°, de Liverpool. »\n",
    "> \n",
    ">  - dans : [Le Petit Journall, 17 avril 1912](https://gallica.bnf.fr/ark:/12148/bpt6k6196931)\n",
    "\n",
    "\n",
    "La première étape est l'**identification** des mentions d'entités à l'intérieur du texte.\n",
    "Cela consiste à **annoter** dans le texte les mots qui sont des mentions d'entités. \n",
    "Ici, l'extrait contient **7 mentions** de **6 entités** :\n",
    "\n",
    "> « Le capitaine <span class =\"renbox\">Smith</span> qui commandait le <span class=\"renbox\">Titanic</span> est, nous l'avons dit hier, depuis plus de 35 ans au service de la <span class =\"renbox\">White Star Line</span>.\n",
    "> Il est actuellement agé de 60 ans.\n",
    ">  Né dans le <span class =\"renbox\">Staffordshire</span>, le capitaine <span class =\"renbox\">Smith</span> avait fait son apprentissage de marin dans la maison d'armement <span class =\"renbox\">Gibson et C°</span>, de <span class =\"renbox\">Liverpool</span>. »\n",
    "> \n",
    "| Entité du monde réel  | Mentions | Nombre de mentions |\n",
    "| :--------------- |:---------------| :---------------|\n",
    "| Le capitaine Edward John Smith | phrase 1 : \"Smith\", phrase 3 : \"Smith\"| 2 | \n",
    "| Le navire transatlantique Titanic | phrase 1 : \"Titanic\" | 1 | \n",
    "| La compagnie maritime White Star Line | phrase 1 : \"White Star Line\" | 1 | \n",
    "| Le comté anglais de Staffordshire | phrase 1 : \"Staffordshire\" | 1 | \n",
    "| La compagnie maritime Gibson & Co | phrase 3 : \"Gibson et C°\" | 1 | \n",
    "| La ville anglaise de Liverpool |  phrase 3 : \"Liverpool\" | 1 | \n",
    "\n",
    "Une fois identifiées, les mentions d'entités sont **classées** à partir d'une catégorisation prédéfinie.\n",
    "\n",
    "Construisons nous une classification à partir de l'extrait et catégorisons les mentions d'entités avec :\n",
    "| N° | Mention  | Classe |\n",
    "| ---------------:| :--------------- |:---------------\n",
    "|1| \"Smith\" | <span class=\"renbox per\">Personne</span>| \n",
    "|2| \"Titanic\" | <span class=\"renbox misc\">Objet</span> | \n",
    "|3| \"White Star Line\" | <span class=\"renbox org\">Organisation</span> | \n",
    "|4| \"Staffordshire\" | <span class=\"renbox loc\">Lieu</span> | \n",
    "|5| \"Smith\" | <span class=\"renbox per\">Personne</span> | \n",
    "|6| \"Gibson et C°\" | <span class=\"renbox org\">Organisation</span> | \n",
    "|7|  \"Liverpool\" |  <span class=\"renbox loc\">Lieu</span>| \n",
    "\n",
    "Les mentions annotées dans le texte peuvent donc être classées :\n",
    "\n",
    "> « Le capitaine <span class =\"renbox per\">Smith<sup>[PERSONNE]</sup></span> qui commandait le <span class=\"renbox misc\">Titanic<sup>[OBJET]</sup></span> est, nous l'avons dit hier, depuis plus de 35 ans au service de la <span class =\"renbox org\">White Star Line<sup>[ORGANISATION]</sup></span>.\n",
    "> Il est actuellement agé de 60 ans.\n",
    ">  Né dans le <span class =\"renbox loc\">Staffordshire<sup>[LIEU]</sup></span>, le capitaine <span class =\"renbox per\">Smith<sup>[PERSONNE]</sup></span> avait fait son apprentissage de marin dans la maison d'armement <span class =\"renbox org\">Gibson et C°<sup>[ORGANISATION]</sup></span>, de <span class =\"renbox loc\">Liverpool<sup>[LIEU]</sup></span>. »\n",
    "\n",
    "\n",
    "## Pourquoi c'est difficile 😰\n",
    "\n",
    "La reconnaissance d'entités nommées est l'une des tâches les plus classiques du traitement automatique du langage naturel car elle est essentielle pour **extraire des connaissances** à partir de textes.\n",
    "\n",
    "Pourtant elle est difficile à réaliser automatiquement pour trois raisons principales : \n",
    "1. **La notion d'entité nommé est assez floue est très dépendante du domaine** et de ce que l'on cherche vraiment à extraire. Par exemple on aurait très bien pu considérer que l'expression complète <span class =\"renbox per\">Le capitaine Smith<sup>[PERSONNE]</sup></span> était une mention d'entité, et pas juste \"Smith.\".\n",
    "2. **Les mentions peuvent être complexes, implicites, et contextuelles**. Dans le contexte de l'extrait, \"le capitaine du navire\" serait une mention de Edward Smith...\n",
    "3. **Les textes eux-mêmes peuvent être complexes**. Avec des documents historiques, une source de difficulté évidente est le **bruit OCR** qui peut rendre difficile l'identification des mentions d'entités. Par exemple :\n",
    "\n",
    "> « Le capiîe Smlth qut commandait le Tîlanic est, nous l’avons dît hîer, depuls , plus de 35 ans au servlce de la Wllhe Slar Llne. Il est actuellemenl agé de 60 ans. Né dans le Slaffordshîre, le capltalne Smlth avall fal son apprentîssage de ma-rln dans la malson d'armemenl Glbson el C, de Llverpooî. . »\n",
    "\n",
    "\n",
    "La reconnaissance d'entités nommées est réalisée grâge à des techniques d'apprentissage automatique depuis les années 2010. Aujourd'hui ce sont les **modèles de langage** qui donnent les meilleurs résultats, mais le problème reste ouvert.\n",
    "\n",
    "Pour autant, ces modèles nécessitent toujours d'être **entraînés** sur un corpus pour que les résultats soient satisfaisants.\n",
    "\n",
    "# B/ Reconnaissance d'entités nommées avec SpaCy\n",
    "\n",
    "## Installation 📦\n",
    "\n",
    "[SpaCy](https://spacy.io/) est une bibliothèque logicielle Python *open source* dédiée au traitement automatique du langage naturel. \n",
    "Elle a l'avantage d'être facile d'utilisation, très documentée, très utilisée, et de mettre à disposition des modèles de langage ayant de bonnes performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par l'installer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "%pip install -q spacy # -q (quiet) pour cacher les messages d'installation peu importants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite l'importer dans le notebook pour l'utiliser dans toutes les cellules suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "import spacy\n",
    "\n",
    "print(\"Version de SpaCy installée : \",spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Télécharger un modèle de langage préentraîné 💾\n",
    "\n",
    "Installer SpaCy a téléchargé la bibiothèque Python, mais pour qu'elle puisse réaliser des tâches de TALN il lui faut avoir accès à un **modèle de langage préentraîné**.\n",
    "\n",
    "Explosion, l'entreprise qui développe SpaCy, en publie plusieurs spécialement entraînés pour des textes en français. On en trouve la liste ici : https://spacy.io/models/fr\n",
    "\n",
    "Les modèles `fr_core_news_X` sont particulièrement intéressants pour nous car ils ont été entraînés sur des corpus de presse (d'où leur nom), et qu'ils sont optimisés pour fonctionner correctement sans carte graphique.\n",
    "\n",
    "Trois modèles sont disponibles, de tailles et de performances croissantes :\n",
    "| Modèle | Taille (Mb)  | Classe |\n",
    "| ---------------:| :--------------- |:---------------\n",
    "|1| `fr_core_news_sm` | 15Mb | \n",
    "|2| `fr_core_news_md` | 43Mb | \n",
    "|3| `fr_core_news_lg` | 545Mb |\n",
    "\n",
    "Nous allons utiliser le modèle `fr_core_news_md` qui - on l'espère - offre un compromis intéressant entre taille (=temps de téléchargement) et performances.\n",
    "\n",
    "\n",
    "Pour rendre son utilisation la plus simple possible, SpaCy mets à disposition des **commandes** qui font beaucoup de travail à notre place.\n",
    "\n",
    "Ainsi, on peut télécharger un modèle en exécutant simplement la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaître des mentions d'entités avec SpaCy 🔍\n",
    "\n",
    "En exécutant la cellule ci-dessous, SpaCy devrait vous avoir signalé :\n",
    "> You can now load the package via spacy.load('fr_core_news_md')\n",
    "\n",
    "C'est en effet avec cette instruction Python que l'on peut charger le modèle de langage en mémoire et initialiser, dans le code, une **chaîne de traitement** (*Pipeline*) SpaCy qui permettra de traiter des textes !\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 1 - ⭐</strong></div>\n",
    "\n",
    "L'appel à `spacy.load(...)` renvoie une \"*Pipeline*\" qu'on pourra ensuite utiliser.\n",
    "Dans la cellule suivante,  chargez le modèle `fr_core_news_md` et stockez la *pipeline* crée dans une variable nommée `nlp`, puis affichez la liste de composants de la *pipeline* que vous pouvez récupérer avec `nlp.pipe_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "\n",
    "# Print the names of the pipeline components\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le composant `ner` est présent, c'est parfait, la *pipeline* est donc capable du faire de la reconnaissance d'entités nommées (NER).\n",
    "\n",
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "\n",
    "Pour traiter un texte, rien de plus simple : il suffit de passer ce texte à la *pipeline* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "texte  = \"\"\"Le capitaine Smith qui commandait le Titanic est, nous l'avons dit hier, depuis plus de 35 ans au service de la White Star Line.\n",
    "Il est actuellement agé de 60 ans.\n",
    "Né dans le Staffordshire, le capitaine Smith avait fait son apprentissage de marin dans la maison d'armement Gibson et C°, de Liverpool.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat du traitement est stocké dans la variable `doc` sous la forme d'un objet `spacy.Doc`. Il s'agit d'une structure qui contient le texte, ainsi que tout ce qui en a été extrait par les différents composants de la *pipeline*.\n",
    "\n",
    "On peut bien sûr accéder au texte lui-même :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "doc.text # Afficher le texte du document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... mais surtout aux **entités nommées** reconnues par le modèle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "doc.ents # Afficher les entités nommées reconnues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y a quelques différences avec notre version \"manuelle\" en introduction : \n",
    "- apparement, le modèle considère la mention \"capitaine Smith\" plutôt que simplement \"Smith\"\n",
    "- au lieu d'une seule mention \"Gibson et C°\", il en a identifié deux séparées : \"Gibson\", et \"C°\".\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 2 - ⭐</strong></div>\n",
    "\n",
    "Et les classes des mentions reconnues alors ?\n",
    "Rapellez-vous, la REN contient deux étapes : l'identification des mentions et leur classification. \n",
    "\n",
    "SpaCy l'a fait, mais ne vous le montre pas en affichant simplement la liste des entitées nommées.\n",
    "En fait, `doc.ents` stocke les entités nommées comme des objets de type `spacy.Span` qui contiennent diverses informations sur l'entité nommée dont:\n",
    "- son contenu avec `ent.text` \n",
    "- sa classe avec `ent.label_` (attention à *l'underscore*)\n",
    "- sa position dans le texte avec `ent.start_char` et `ent.end_char`\n",
    "\n",
    "\n",
    "Complétez la cellule suivante pour afficher la liste des entités reconnues et leur classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "# Afficher les entités nommées reconnues avec leur label\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi constater que l'entité nommée \"Gibson\" a été mal classée par le modèle comme une personne (PER), car dans ce contexte \"Gibson et C°\" est une entreprise.\n",
    "\n",
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "On voit que le composant NER a attribué lui-même les classes PER, MISC et LOC sans qu'on ne lui en ai jamais donné la liste.\n",
    "Ces classes sont prédéfinies car le composant NER du modèle `fr_core_news_md` a été entraîné spécifiquement pour les détecter.\n",
    "On peut en avoir la liste complète ainsi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "nlp.pipe_labels[\"ner\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'il existe aussi une classe nommée ORG...mais que désigne t-elle ? Et MISC ?\n",
    "On peut le savoir grâce à `spacy.explain(LABEL)` où LABEL est une des classes connues.\n",
    "Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "spacy.explain(\"ORG\") # N'hésitez pas à voir la signification des autres labels !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutôt que de lister les entités nommées reconnues, on peut aussi les afficher directement comme des annotations dans le texte grâce au visualiseur de SpaCY nommé `displacy`.\n",
    "\n",
    "Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "from spacy import displacy #On importe la fonction displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\") # style=\"ent\" indique que l'on veut afficher les entités nommées reconnues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B/ Créer des données d'entraînement pour un modèle SpaCy spécialisé sur la presse française ancienne OCRisée\n",
    "\n",
    "## Les limites d'un modèle \"sur étagère\" 🧱\n",
    "\n",
    "Nous avons vu dans avec le texte d'exemple que la *pipeline* SpaCy, quoique relativement performante, faisait des erreurs pourtant évidentes:\n",
    "- \"White Star Line\" devrait être classé comme ORG et non comme MISC;\n",
    "- \"Gibson et C°\" devrait être une seule mention de classe ORG.\n",
    "\n",
    "Et à votre avis, que se passe t-il avec du texte bruité par un OCR ? Exécutez la cellule suivante pour le savoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    " \n",
    "texte_ocr = \"\"\"Le capiîe Smlth qut commandait le Tîlanic est, nous l’avons dît hîer, depuls , plus de B5 ans au servîce de la Whîte Star Lîne.\n",
    "Il est actueîlement âgé de 60 ans.\n",
    "Né dans le Staffordshire, le capiîe Smitn avatt fat son apprentîssage de marîn dans la maîson d'armement Gtbson et C°, de Lîverpool.\"\"\"\n",
    "\n",
    "# Il tente de déchiffrer un texte MÉCONNAISSABLE après OCR... Le résultat va vous CHOQUER ! 🔥😱\n",
    "displacy.render( nlp(texte_ocr), style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi est-ce aussi mauvais ? Tout simplement car les modèles de SpaCy n'ont pas été entraînés sur des textes dégradés par l'OCR et sont donc incapables de comprendre la sémantique de tels textes.\n",
    "\n",
    "Pour surmonter ce problème, une seule solution : **entraîner notre propre modèle** !\n",
    "\n",
    "## Des données, toujours des données 🗃️\n",
    "\n",
    "Qui dit entraînement dit apprentissage, et qui dit apprentissage dit exemples. En l'occurence, nous avons besoin de textes de presse anciens annotés d'entités nommées.\n",
    "\n",
    "Le nerfs de la guerre de l'apprentissage automatique, ce sont les données d'entraînement : elles sont rares, coûteuses à produire (à la main ou - aujourdhui - assisté par un LLM)...\n",
    "\n",
    "Mais comme nous sommes chanceux, la BnF a publié en 2015 dans le cadre du projet Europeana Newspaper (!) 212 extraits de presse ancienne annotés : https://api.bnf.fr/fr/texte-de-presse-annote-en-entites-nommees\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 3 - ⭐</strong></div>\n",
    "\n",
    "Rendez-vous sur https://api.bnf.fr/fr/texte-de-presse-annote-en-entites-nommees et :\n",
    "1. En suivant le lien \"Textes annotés et modèle (Europeana Newspapers, 50 Mo)\", téléchargez l'archive **EN-REN.zip**\n",
    "2. Décompressez son contenus dans le dossier `data/` déjà créé à coté de ce notebook.\n",
    "3. Le Résultat doit être un dossier `partie_1/data/Training Data Set` contenant 212 fichiers `.tag`  \n",
    "\n",
    "Vérifiez que les fichiers sont au bon endroit en exécutant la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! ls -C \"../data/Training Data Set\" | grep .tag # Doit afficher la liste de fichiers .tag dans le dossier ./data/Training Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "Regarder le contenu d'un des ces fichiers .tag, qui sont simplement des fichiers textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! head -n 50 \"../data/Training Data Set/axaa.H.a.tag\" # La commande shell head permet d'afficher les premières lignes d'un fichier (ici 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que voit-on ?\n",
    "1. Le texte est découpé en mots, et chaque mot est placé sur une ligne\n",
    "2. Chaque ligne contient deux informations : le mot, et une étiquette\n",
    "3. Les étiquettes visibles dans les 50 premières lignes sont **O**, **I-PERS** et **I-LIEU**\n",
    "\n",
    "Ce format, pensé pour la reconnaissance d'entités nommées, se nomme **IO**.\n",
    "Prenons quelques minutes pour le comprendre.\n",
    "\n",
    "## Le format Inside-Outside (IO) pour les textes annotés d'entités nommées 🗟\n",
    "<style>\n",
    "    .renbox {\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        padding: 2px;\n",
    "        margin: 3px;\n",
    "        border-radius: 3px;\n",
    "        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        font-weight: bolder;\n",
    "        background-color: #8b8c8b;\n",
    "    }\n",
    "    .per {\n",
    "        background-color: #ffb654;\n",
    "    }\n",
    "    .org {\n",
    "        background-color: #49ace6;\n",
    "    }\n",
    "    .misc {\n",
    "        background-color: #c2ccd1;\n",
    "    }\n",
    "    .loc {\n",
    "        background-color: #3deb6c;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "\n",
    "Inside-Outside permet de stocker facilement des entités nommées annotées dans un texte préalablement découpé en mots (les caractères de ponctuation sont considérés comme des mots également).\n",
    "\n",
    "Le principe est le suivant :\n",
    "- tout mot qui fait partir d'une entité nommée de classe \"CLASSE\" est étiquetée par \"I-CLASSE\" - on dit qu'elle est **à l'intérieur** (*inside*, \"I-\") de l'entité nommée ;\n",
    "- tous les autres mots sont étiquetés par \"O\", ils sont **en dehors** (*outside*) des entités nommées du texte.\n",
    "\n",
    "Une manière intuitive de comprendre ce formatage est d'imaginer qu'on surligne les entités nommées dans le texte avec des surligneurs de couleurs différentes, chaque couleur correspondant à une classe.\n",
    "Les mots surlignés sont notés \"I\", et ceux non surlignés \"O\".\n",
    "\n",
    "L'extrait du fichier `axaa.H.a.tag` ci-dessus correspond donc au texte annoté :\n",
    "\n",
    "> \n",
    "> ==>\n",
    "> /Volumes/Num_TRAV$/Europeana Newspapers/NER_corpus_validation-oct2014/Extraction_pour_annotation/EXTRACTION_2/0641047/txt/X0000001.txt\n",
    "> <==\n",
    "> \n",
    "> e <span class =\"renbox per\">Emmanuel DESOLES<sup>PERS</sup></span> de LOU Directeur politique BÊ>ÀCTION ET ADMINISTRATION 9& , e <span class =\"renbox loc\">Rue du Pré-Botté<sup>LIEU</sup></span>, aS e <span class =\"renbox loc\">RENNES<sup>LIEU</sup></span> ABONNEMENTS Dép\n",
    "\n",
    "<span style=\"color: #40d6d1; font-size: 1.2em;\"><strong>💡 Astuce |</strong></span> Il existe d'autres formats, avec leurs avantages et inconvénients. Nous n'irons pas plus loin ici, mais cet article du site Medium en fait une présentation efficace : https://medium.com/@muskaan.maurya06/name-entity-recognition-and-various-tagging-schemes-533f2ac99f52\n",
    "\n",
    "\n",
    "<span style=\"color: red; font-size: 1.2em;\"><strong>🚨 Attention |</strong></span> Avez-vous remarqué que les classes du fichier annoté ne correspondent pas à celles du modèle SpaCy  (LOC, PER, ORG, MISC) ? On voit PERS et non PER pour étiqueter les mentions de personnes, LIEU et non LOC pour les lieux.\n",
    "Est-ce un problème ? Oui ! Le modèle n'a aucune idée de la sémantique réelle derrière les classes, il n'aura aucun moyen de savoir que PERS et PER sont sensés désigner la même catégorie d'entités ! \n",
    "Nous aurons plus loin besoin d'harmoniser les classes pour Spacy avant des les utiliser pour entraîner un modèle. !\n",
    "\n",
    "En découle un fait fondamental : Il est bien sûr possible de déclarer ses propres classes, inconnue du modèle, mais elles devront être **apprises totalement, sans connaissance préalable** et nécessiteront sans doute **plus d'exemples d'entraînement** pour que le modèle apprenne suffisamment bien à les reconnaître.\n",
    "\n",
    "\n",
    "## Un fichier pour les assembler tous 📃\n",
    "\n",
    "Pour se simplifier la tâche, commençons par rassembler tous les fichiers .tag en un seul grand fichier d'entraînement.\n",
    "\n",
    "Nous pourrions le faire avec Python, mais puisque Jupyter permet d'exécuter des commandes Shell à l'aide de la *magic command* '!', autant en profiter et utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! cat \"../data/Training Data Set/\"*.tag > \"training_dataset.tag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La commande `cat` renvoie le contenu des fichiers en paramètre, ici tous les fichiers finissant par .tag dans le dossier ./data/Training Data Set\n",
    "- '>' sert à rediriger la sortie de la commande précédente, ici le contenu de tous les fichiers .tag affichés par `cat`\n",
    "- la sortie est redirigée vers un fichier nommé \"training_dataset.tag\"\n",
    "\n",
    "## Harmonisation des classes d'entités nommées et séparation des phrases 🧹\n",
    "\n",
    "Les classes d'entités nommées annotées dans les fichier .tag sont PERS, LIEU et ORG, qui correspondent respectivement aux classes de SpaCy PER, LOC et ORG.\n",
    "\n",
    "Pour que le modèle s'y retrouve, nous devons donc retoucher le fichier training_dataset.tag et remplacer toutes les occurrences des classes initiales par les classes SpaCy.\n",
    "\n",
    "En plus, la [documentation de SpaCy](https://spacy.io/api/cli#convert) indique que dans le format IO, les phrases doivent être séparées par des lignes vides - ce qui n'est pas le cas dans les fichiers .tag.\n",
    "Nous devons donc insérer des lignes vides après chaque fin de phrase.\n",
    "\n",
    "N'étant ni passionnantes ni l'objectif pédagogique de la séance, le code de ces opérations de pré-traitement vous est donné directement dans la cellule ci-dessous, à exécuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "# Liste de remplacement , [(ancien_label, nouveau_label), ...]\n",
    "mapping = [\n",
    "    (\"I-LIEU\", \"I-LOC\"),\n",
    "    (\"I-PERS\", \"I-PER\"),\n",
    "    (\"I-ORG\", \"I-ORG\")\n",
    "]\n",
    "\n",
    "# On ouvre le fichier en mode lecture...\n",
    "with open(\"training_dataset.tag\", \"r\") as file:\n",
    "    training_dataset = file.read()\n",
    "    # ... on remplace les labels anciens par les nouveaux ...\n",
    "    for k, v in mapping:\n",
    "        training_dataset = training_dataset.replace(k, v) \n",
    "\n",
    "    # ... et on insère des lignes vides(2 retours à la ligne) à chaque marqueur de fin de phrase, ie. une ligne \". O\"\n",
    "    import re\n",
    "    training_dataset = re.sub(r\"(\\n\\.\\tO)\", r\"\\1\\n\", training_dataset)\n",
    "\n",
    "# Finalement, on ouvre le fichier en mode écriture et on écrit le contenu modifié\n",
    "with open(\"training_dataset.tag\", \"w\") as file:\n",
    "    file.write(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier que l'opération semble s'être bien passée en regardant le début du fichier grâce à la commande Shell `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi !  🚀\n",
    "\n",
    "# Les 50 premières lignes du fichier \"training_dataset.tag\"\n",
    "! head -n 50 \"training_dataset.tag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation en documents SpaCy 🪄\n",
    "\n",
    "Évidemment, SpaCy ne sait pas lire le format IO mais uniquement son format propre - ce serait trop simple.\n",
    "Heureusement, la bibliothèque fournit une commande de conversion : `spacy convert` (doc : https://spacy.io/api/cli#convert )\n",
    "\n",
    "Décomposons la commande complète dont nous avons besoin :\n",
    "```bash\n",
    "python -m spacy convert -c ner  -n 10 -b fr_core_news_md \"training_dataset.tag\" .\n",
    "```\n",
    "- l'option `-c ner` indique à SpaCy que le format de training_dataset.tag est IO ou similaire, en tout cas un format d'annotations de reconnaissance d'entités nommées ;\n",
    "- Avec `-n 10`, Spacy va découper le jeu de données en groupes de 10 phrases, chaque groupe sera un exemple d'entraînement.\n",
    "- `-b fr_core_news_md` spécifie à SpaCy qu'il doit utiliser le modèle `fr_core_news_md` pour effectuer la transformation. Il a besoin de connaître le modèle car chaque mot va être codé par un identifiant, et c'est le modèle qui fournit cela.\n",
    "\n",
    "Appliquons la conversion pour produire un nouveau fichier `training_dataset.spacy`, au format SpaCy.\n",
    "\n",
    "<span style=\"color: red; font-size: 1.2em;\"><strong>🚨 Attention |</strong></span> La commande ci-dessus doit produire un fichier contenant **1191 documents**. SI ce n'est pas le cas, signalez-le !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! python -m spacy convert -c ner  -n 10 -b fr_core_news_md \"training_dataset.tag\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouf, nous avons enfin notre fichier principal d'entraînement !\n",
    "\n",
    "En a t-on fini ? Presque mais pas tout à fait : il faut encore séparer le fichier en deux sous-ensembles d'exemples : les **exemples d'entraînement** et les **exemples d'évaluation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu d'entraînement, jeu d'évaluation, jeu de test 🗂️\n",
    "\n",
    "Lors de son entraînement, un modèle va exploiter un ensemble d'exemples qu'on lui aura fourni; ces exemples forment le **jeu (de données) d'entraînement** du modèle.\n",
    "\n",
    "Durant l'entraînement, le modèle va régulièrement mesurer sa performance en comparant ses prédictions d'entités nommées avec des exemples.\n",
    "Mais **on ne veut pas que ces exemples proviennent du jeu d'entraînement**.\n",
    "Pourquoi ? Parce que s'il fait cela, il apprendra **par coeur** ses exemples d'entraînement et n'apprendra pas à **généraliser**, c'est à dire à dégager une sémantique de plus haut niveau qui lui permettra de \"comprendre\" correctement des textes.\n",
    "\n",
    "Pour résoudre le problème, on isole un ensemble d'exemples qui forme un **jeu d'évaluation**, sur lequel le modèle n'apprends pas directement mais qu'il utilisera pour tester ses performances en cours d'apprentissage.\n",
    "\n",
    "Enfin, il est important de conserver une partie des données totalement hors du processus d'apprentissage pour pouvoir **tester** les performances du modèle en **situation réelle**, c'est à dire en le confrontant à des exemples qu'il n'aura jamais vu. On appelle cet ensemble le **jeu de test**.\n",
    "\n",
    "<span style=\"color: #fc03d3; font-size: 1.2em;\"><strong>📝 À retenir |</strong></span>\n",
    "Pour résumer : \n",
    "- le modèle apprends à reconnaître des entités nommées dans les exemples du **jeu d'apprentissage** ;\n",
    "- pour vérifier qu'il apprends correctement, il mesure ses performances face à des exemples différents appelés **jeu d'évaluation**.\n",
    "- on garde des exemples complètement hors du circuit d'apprentissage pour tester les capacités du modèle une fois entraîné:  c'est le **jeu de test**.\n",
    "\n",
    "\n",
    "En règle générale, on conserve environ 80% du jeu de données total comme jeu d'entraînement, et donc 20% comme jeu d'évaluation.\n",
    "Ici, on commencera par séparer 10% du corpus générale en un jeu de test, pour appliquer la règle des 80/20% sur le reste.\n",
    "\n",
    "Il faut donc séparer le fichier `train_dataset.spacy` en trois nouveaux fichiers : `test.spacy` qui contiendra 10% du total des documents, `train.spacy` qui contiendra 80% des documents restants, et `evaluation.spacy` qui contiendra les 20 autres %.\n",
    "\n",
    "Nous pourrions faire cela à la main ... mais nous pouvons aussi faire appel à la fonction `train_test_split` de la bibliothèque Python `scikit-learn` qu'il nous faut installer (doc : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "%pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `train_test_split`  accepte deux arguments principaux : \n",
    "- une liste d'exemples à séparer\n",
    "- une option `train_size=...` ou `test_size=...` qui prend un nombre entre 0 et 1 représentant la fraction d'exemples qui doivent composer le  jeu d'entraînement, ou de test (d'évaluation, pour nous).\n",
    "\n",
    "Cette fonction renvoie un tuple contenant **deux listes** : (1) la liste des  exemples d'entraînement et (2) la liste des exemples d'évaluation.\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 4 - ⭐⭐</strong></div>\n",
    "\n",
    "Complétez puis exécutez le code suivant pour séparer les documents dans `tranining_dataset.spacy` en deux ensembles :\n",
    "- `docs_test` doit contenir 10% des exemples ;\n",
    "- `doc_train_evaluation` doit contenir les 90% restants\n",
    "\n",
    "Ensuite, séparez de nouveau `doc_train_evaluation` en deux ensembles : \n",
    " - `train.spacy` doit contenir 80% des exemples ;\n",
    " - `evaluation.spacy` doit contenir les 20% restants ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "from spacy.tokens import DocBin # DocBin est une classe qui représente un jeu de données SpaCy\n",
    "from sklearn.model_selection import train_test_split  # sci-kit learn s'importe sous le nom sklearn\n",
    "\n",
    "# Chargement du jeu de données SpaCy des textes annotés\n",
    "jeu_complet = DocBin().from_disk(\"training_dataset.spacy\")\n",
    "\n",
    "# Chargement du modèle de langue SpaCy pour le français\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "\n",
    "# Récupération des documents du jeu de données sous forme de liste\n",
    "docs = list(jeu_complet.get_docs(nlp.vocab))\n",
    "\n",
    "# Complétez ici en appellant la fonction train_test_split de scikit-learn !\n",
    "# Étape 1 : séparation en deux listes : `docs_test` (10%) et `docs_train_evaluation` (90%)\n",
    "# Étape 2 : séparation de `docs_train_evaluation` en deux listes : `docs_train` (80%) et `docs_evaluation` (20%)\n",
    "docs_test, docs_train_evaluation = train_test_split(docs, train_size=0.1)\n",
    "docs_train, docs_evaluation = train_test_split(docs_train_evaluation, train_size=0.8)\n",
    "\n",
    "# Export des jeux de données d'entraînement et de test\n",
    "DocBin(docs=docs_train).to_disk(\"train.spacy\")\n",
    "DocBin(docs=docs_evaluation).to_disk(\"evaluation.spacy\")\n",
    "DocBin(docs=docs_test).to_disk(\"test.spacy\")\n",
    "\n",
    "# Afficher la taille des jeux de données d'entraînement et d'évaluation\n",
    "print(\"Taille du jeu d'entraînement : \", len(docs_train))\n",
    "print(\"Taille du jeu d'évaluation : \", len(docs_evaluation))\n",
    "print(\"Taille du jeu de test : \", len(docs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "Vérifions enfin que le répertoire courant contient bien les deux fichiers utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! ls -lh train.spacy evaluation.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouf ! Nous voilà prêts pour le moment de vérité : **l'entraînement du modèle !**.\n",
    "\n",
    "# C/ Entraîner un modèle SpaCy spécialisé sur la presse française ancienne OCRisée\n",
    "\n",
    "Contrairement aux modèles Transfromers (BERT, etc.), les modèles `core` de SpaCy (comme `fr_core_news_x`) ne sont pas adaptés au *fine-tuning*, c'est à dire à la spécialisation d'un modèle déjà entraîné : avec les modèles `core`, on entraîne *from scratch*.\n",
    "\n",
    "\n",
    "## Configuration de l'entraînement ⚙️ \n",
    "\n",
    "Le paramètrage de l'entraînement d'un modèle SpaCy se fait à l'aide de fichiers de configuration.\n",
    "Heureusement, on trouve à la page [https://spacy.io/usage/training ](https://spacy.io/usage/training), section *Quickstart*, un assistant de création de tels fichiers.\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 5 - </strong></div>\n",
    "\n",
    "Avec l'assistant, créer un fichier pour le **français**, contenant le composant **ner**, pour **CPU** et optimisé pour **l'efficience**.\n",
    "\n",
    "Téléchargez le fichier produit (le bouton est en bas à droite du *widget*) et placez-le dans le dosser de travail `partie_1/`.\n",
    "\n",
    "La documentation nous dit d'exécuter ensuite la commande SpaCy suivante pour produire le fichier de configuration complet à partir du fichier téléchargé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "\n",
    "## On entraîne ! 🔥🚀\n",
    "\n",
    "Tout est prêt, nous avons :\n",
    "-  le fichier de configuration complet `config.cfg`\n",
    "-  le jeu d'entraînement `train.spacy`\n",
    "-  le jeu d'évaluation `evaluation.spacy`\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 6 - ⭐</strong></div>\n",
    "\n",
    "Servez-vous du message de sortie de la commande précédente pour lancer l'entraînement.\n",
    "\n",
    "Utilisez l'option `--output` pour **sauvegarder le modèle enbtraîné dans le dossier `ner_presse_ancienne/`**\n",
    "\n",
    "<span style=\"color: #85d0ff; font-size: 1.2em;\"><strong>ℹ️ Info |</strong></span> Le jeu d'évaluation est désigné dans SpaCy par le terme \"dev\", pour \"dévelopment\" - mais c'est bien notre jeu d'évaluation qu'il faut utiliser !\n",
    "\n",
    "<span style=\"color: red; font-size: 1.2em;\"><strong>🚨 Attention |</strong></span> Si l'entraînement est trop lent, basculez sur Google Colab et **demandez de l'aide** 🙋."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "# Lancez l'entraînement du modèle NER !\n",
    "! python -m spacy train config.cfg --paths.train train.spacy --paths.dev evaluation.spacy --output ./ner_presse_ancienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durant l'entraînement SpaCy affiche tous les K itérations un ensemble de valeurs,par exemple : \n",
    "```raw\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     64.29    0.09    0.17    0.06    0.00\n",
    "  0     200        162.71   2838.80   40.70   52.57   33.20    0.41\n",
    "  0     400         96.11   1467.98   49.21   65.45   39.43    0.49\n",
    "```\n",
    "\n",
    "Sans entrer dans les détails qui dépasseraient l'objectif de cet atelier, deux choses sont à retenir:\n",
    "1. l'entraînement d'un modèle statistique est un problème d'**optimisation** où l'on cherche à minimiser une **fonction de coût** (LOSS) qui mesure l'écart entre les prédictions du modèle et les exemples qui lui sont donnés. C'est la valeur donnée par `LOSS NER`.\n",
    "2. le jeu d'évaluation est utilisé en cours d'apprentissage pour mesurer la propension du modèle à identifier et classer les entités nommées attendues. Ce sont les mesures `ENTS_F`, `ENTS_P` et `ENTS_R`. Nous verrons plus loin ce que les suffixes `_F`, `_P` et `_R` signifient.\n",
    "\n",
    "<span style=\"color: #fc03d3; font-size: 1.2em;\"><strong>📝 À retenir |</strong></span>\n",
    "En bref, le modèle améliore ses performances lorque :  \n",
    "- LOSS LOTK2VEC et LOSS NER **diminuent**\n",
    "- ENTS_F, ENTS_P  et ENTS_R **augmentent**\n",
    "\n",
    "\n",
    "\n",
    "Regardons finalement ce qui a été exporté par Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! tree -L 2 ./ner_presse_ancienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que Spacy a en réalité exporté **deux modèles** :\n",
    "- `model_best/` contient le modèle ayant montré les meilleures performances durant les itérations d'entraînement (ie. la ligne du tableau d'entraînement avec les meilleures mesures ENTS) ;\n",
    "- `model_last/` contient le modèle à la fin de l'entraînement. \n",
    "\n",
    "<span style=\"color: #fc03d3; font-size: 1.2em;\"><strong>📝 À retenir |</strong></span> L'entraînement d'un modèle est un processus stochastique, le modèle produit en fin de processus n'est pas nécessairement le meilleur !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation quantitative du modèle 💯\n",
    "\n",
    "Évaluer les performances d'un modèle sur des données **qu'il n'a jamais vu lors de son entraînement** est une étape essentielle de toute procédure d'entraînement.\n",
    "Cela mesure sa capacité à **généraliser** ce qu'il a appris pour de nouveaux textes. \n",
    "\n",
    "Nous allons pour cela faire appel au **jeu de test** créé précédement et utiliser la commande `spacy benchmark accuracy` (https://spacy.io/api/cli#benchmark-accuracy) pour tester les performances du meilleur modèle (stocké dans `ner_presse_ancienne/model-best/`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécutez-moi ! 🚀\n",
    "\n",
    "! python -m spacy benchmark accuracy ner_presse_ancienne/model-best/ test.spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat devrait ressembler à ceci  :\n",
    "```raw\n",
    "================================== Results ==================================\n",
    "TOK     -    \n",
    "NER P   69.72\n",
    "NER R   64.39\n",
    "NER F   66.95\n",
    "SPEED   41713\n",
    "=============================== NER (per type) ===============================\n",
    "          P       R       F\n",
    "LOC   76.02   62.14   68.38\n",
    "ORG   50.38   42.58   46.15\n",
    "PER   70.24   75.64   72.84\n",
    "```\n",
    "\n",
    "Comment interprêter ce rendu un peu obscur ?\n",
    "Regardons d'abord la section `====Results====`, qui mesure la qualité globale de la reconnaissance des entités dans les textes du **jeu de test**.\n",
    "\n",
    "Les lettres `P`, `R` et `F` sont des abbréviations de trois métriques de qualité très communément utilisées pour ce type de tâche :\n",
    "\n",
    "|Abbréviation|Nom|Description|\n",
    "|:------|:------|---------|\n",
    "|P| Précision |\tPourcentage d'entités nommées prédites par le modèle qui étaient effectivement dans le jeu de test. Une précision élevée signifie que lorsque le modèle prédit une entité nommée, il a souvent raison. |\n",
    "|R| Rappel\t| Pourcentage des entités nommées du jeu de test que le modèle a effectivement trouvé. Un rappel élevé signifie que le modèle a trouvé la majorité des entités nommées du jeu de test |  \n",
    "|F| F-Score|\tLa moyenne harmonique de la précision et du rappel, mélange les deux mesures en un unique score. |\n",
    "\n",
    "Nous pouvons donc interprêter les résultats ainsi : \n",
    "- 69.72% des prédictions du modèle étaient correctes ;\n",
    "-  il a trouvé 64.39% des entités nommées du jeu de test ;\n",
    "- sa performance générale de reconnaissance est de 66.95 / 100 (sans unité)\n",
    "\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 6 - ⭐</strong></div>\n",
    "\n",
    "Sachant cela, comment interprétez-vous la section `==== NER (per type) ===` ?\n",
    "\n",
    "Qu'est-ce qui pourrait expliquer que les résultats ne soient pas meilleurs ? Discutons-en ensemble ! 🙋\n",
    "\n",
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "\n",
    "<span style=\"color: #fc03d3; font-size: 1.2em;\"><strong>📝 À retenir |</strong></span> \n",
    "- Une **précision** élevée est importante si on veut **éviter les fausses détection** ;\n",
    "- Un **rappel** élevé est important si on on **éviter d'oublier des entités nommées** ;\n",
    "- Un **F-score** élevé est important si on veut concilier précision et rappel !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation qualitative du modèle 👀\n",
    "\n",
    "\n",
    "Si l'évaluation quantitative d'un modèle est essentielle, observer qualitativement ses performances sur des exemples est également crucial pour mieux comprendre ses erreurs.\n",
    "\n",
    "<div style=\"border-top: 1px solid #ff9800; padding: 10px; border-radius: 5px; color:#ff9800;\"><strong>🧩 - QUESTION 7 - ⭐</strong></div>\n",
    "\n",
    "Complétez la cellule suivante pour tester le modèle entraîné sur l'extrait OCRIsé de l'article sur le naufrage du Titanic **et afficher le texte annoter avec displacy**\n",
    "\n",
    "Les résultats sont-ils meilleurs qu'avec le modèle `fr_core_news_md` ? Où sont les erreurs s'il en reste ? Comment les expliquer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez-moi ! 🏗️\n",
    "\n",
    "texte_ocr = \"\"\"Le capiîe Smlth qut commandait le Tîlanic est, nous l’avons dît hîer, depuls , plus de B5 ans au servîce de la Whîte Star Lîne.\n",
    "Il est actueîlement âgé de 60 ans.\n",
    "Né dans le Staffordshire, le capiîe Smitn avatt fat son apprentîssage de marîn dans la maîson d'armement Gtbson et C°, de Lîverpool.\"\"\"\n",
    "\n",
    "nlp = spacy.load('ner_presse_ancienne/model-best')\n",
    "\n",
    "displacy.render(nlp(texte_ocr), style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 1px solid #ff9800; padding: 10px; border-radius: 5px; margin-top: -30px;\"></div>\n",
    "\n",
    "# Ouf, c'est fini ! 🏁\n",
    "\n",
    "C'est tout pour cette fois, vous voici arrivé(e)s au bout, félicitations ! 🎉🎉\n",
    "\n",
    "<span style=\"color: red; font-size: 1.2em;\"><strong>🚨 Attention |</strong></span> Conservez le dossier `ner_presse_ancienne/`, vous en aurez besoin pour la prochaine séance !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
